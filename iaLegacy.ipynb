{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "kerSize = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/mnt/s/Proyects/dataset/train/outdoor\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/mnt/s/Proyects/dataset/val\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Encoder\n",
    "model.add(Conv2D(32, kernel_size=3, strides=2, padding='same',input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Conv2D(256, kernel_size=3, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "\n",
    "# Decoder\n",
    "model.add(Conv2D(256, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(UpSampling2D(size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(UpSampling2D(size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(UpSampling2D(size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Conv2D(1, kernel_size=3, strides=1, padding='same', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, epochs=100, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd42440c310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "[[[[0.9962069 ]\n",
      "   [0.99943143]\n",
      "   [0.99970514]\n",
      "   ...\n",
      "   [0.9996489 ]\n",
      "   [0.99973613]\n",
      "   [0.9977763 ]]\n",
      "\n",
      "  [[0.99940693]\n",
      "   [0.9999218 ]\n",
      "   [0.9999311 ]\n",
      "   ...\n",
      "   [0.99989796]\n",
      "   [0.9999424 ]\n",
      "   [0.99952173]]\n",
      "\n",
      "  [[0.99958867]\n",
      "   [0.99990296]\n",
      "   [0.99987674]\n",
      "   ...\n",
      "   [0.99987173]\n",
      "   [0.99989665]\n",
      "   [0.9996567 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.99974006]\n",
      "   [0.999933  ]\n",
      "   [0.99989533]\n",
      "   ...\n",
      "   [0.9998965 ]\n",
      "   [0.9999201 ]\n",
      "   [0.99969673]]\n",
      "\n",
      "  [[0.9997762 ]\n",
      "   [0.9999701 ]\n",
      "   [0.9999366 ]\n",
      "   ...\n",
      "   [0.99995744]\n",
      "   [0.999956  ]\n",
      "   [0.99976665]]\n",
      "\n",
      "  [[0.9973079 ]\n",
      "   [0.99971944]\n",
      "   [0.999529  ]\n",
      "   ...\n",
      "   [0.99963415]\n",
      "   [0.9994777 ]\n",
      "   [0.9968527 ]]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Cargar la imagen\n",
    "img = cv2.imread(\"/mnt/s/Proyects/dataset/val/outdoor/scene_00022/scan_00193/00022_00193_outdoor_000_020.png\")\n",
    "\n",
    "# Escalar la imagen\n",
    "img = cv2.resize(img, (256, 256))\n",
    "\n",
    "# Normalizar la imagen\n",
    "img = np.float32(img) / 255.0\n",
    "\n",
    "# Agregar una dimensión adicional para representar el lote (batch)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = np.expand_dims(img, axis=-1)\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model = tf.keras.models.load_model('model2.h5')\n",
    "\n",
    "# Realizar la predicción de profundidad\n",
    "depth = model.predict(img)\n",
    "\n",
    "# Imprimir la profundidad predicha\n",
    "print(depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(depth))\n",
    "# print(len(depth[0]))\n",
    "# print(len(depth[0][0]))\n",
    "# print(len(depth[0][0][0]))\n",
    "# print(depth[0][0][0][0])\n",
    "\n",
    "for i in range(128):\n",
    "    for j in range(128):\n",
    "        depth[0][i][j][0] = depth[0][i][j][0]*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_pic = np.reshape(depth, (128, 128))\n",
    "\n",
    "# print(new_pic)\n",
    "\n",
    "# print(len(new_pic))\n",
    "# print(len(new_pic[0]))\n",
    "# print(len(new_pic[0][0]))\n",
    "# print(len(new_pic[0][0][0]))\n",
    "# print(new_pic[0][0][0][0])\n",
    "\n",
    "# for i in range(128):\n",
    "#     for j in range(128):\n",
    "#         new_pic[i][j][0] = depth[0][i][j][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[254.03276 254.85501 254.9248  ... 254.91048 254.93271 254.43297]\n",
      " [254.84877 254.98006 254.98244 ... 254.97398 254.98532 254.87804]\n",
      " [254.89511 254.97525 254.96857 ... 254.96729 254.97365 254.91245]\n",
      " ...\n",
      " [254.93372 254.98291 254.97331 ... 254.97362 254.97963 254.92267]\n",
      " [254.94293 254.99237 254.98383 ... 254.98915 254.98878 254.94049]\n",
      " [254.3135  254.92845 254.8799  ... 254.90671 254.8668  254.19743]]\n"
     ]
    }
   ],
   "source": [
    "print(new_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img = Image.fromarray(new_pic, 'RGB')\n",
    "img.save('my.png')\n",
    "img.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
