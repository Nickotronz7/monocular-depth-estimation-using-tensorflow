{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "kerSize = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/mnt/s/Proyects/dataset/train/outdoor\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/mnt/s/Proyects/dataset/val\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Encoder\n",
    "model.add(Conv2D(32, kernel_size=3, strides=2, padding='same',input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Conv2D(256, kernel_size=3, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "\n",
    "# Decoder\n",
    "model.add(Conv2D(256, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(UpSampling2D(size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(UpSampling2D(size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(UpSampling2D(size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Conv2D(1, kernel_size=3, strides=1, padding='same', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, epochs=100, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Cargar la imagen\n",
    "img = cv2.imread(\"/mnt/s/Proyects/dataset/val/outdoor/scene_00022/scan_00193/00022_00193_outdoor_000_020.png\")\n",
    "\n",
    "# Escalar la imagen\n",
    "img = cv2.resize(img, (256, 256))\n",
    "\n",
    "# Normalizar la imagen\n",
    "img = np.float32(img) / 255.0\n",
    "\n",
    "# Agregar una dimensión adicional para representar el lote (batch)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = np.expand_dims(img, axis=-1)\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "# model = tf.keras.models.load_model('path/to/model.h5')\n",
    "\n",
    "# Realizar la predicción de profundidad\n",
    "depth = model.predict(img)\n",
    "\n",
    "# Imprimir la profundidad predicha\n",
    "print(depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(depth))\n",
    "print(len(depth[0]))\n",
    "print(len(depth[0][0]))\n",
    "print(len(depth[0][0][0]))\n",
    "print(depth[0][0][0][0])\n",
    "\n",
    "for i in range(128):\n",
    "    for j in range(128):\n",
    "        depth[0][i][j][0] = depth[0][i][j][0]*255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "w, h = 512, 512\n",
    "data = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "data[0:256, 0:256] = [255, 0, 0] # red patch in upper left\n",
    "img = Image.fromarray(data, 'RGB')\n",
    "img.save('my.png')\n",
    "img.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
