{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_folder = \"/dataset/\"\n",
    "if not os.path.exists(os.path.abspath(\".\") + annotation_folder):\n",
    "    annotation_zip = tf.keras.utils.get_file(\n",
    "        \"val.tar.gz\",\n",
    "        cache_subdir=os.path.abspath(\".\"),\n",
    "        origin=\"http://diode-dataset.s3.amazonaws.com/val.tar.gz\",\n",
    "        extract=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"val/indoors\"\n",
    "\n",
    "filelist = []\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        filelist.append(os.path.join(root, file))\n",
    "\n",
    "filelist.sort()\n",
    "data = {\n",
    "    \"image\": [x for x in filelist if x.endswith(\".png\")],\n",
    "    \"depth\": [x for x in filelist if x.endswith(\"_depth.npy\")],\n",
    "    \"mask\": [x for x in filelist if x.endswith(\"_depth_mask.npy\")],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "LR = 0.0002\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data, batch_size=6, dim=(768, 1024), n_channels=3, shuffle=True):\n",
    "        \"\"\"\n",
    "        Initialization\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.indices = self.data.index.tolist()\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.min_depth = 0.1\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.data) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if (index + 1) * self.batch_size > len(self.indices):\n",
    "            self.batch_size = len(self.indices) - index * self.batch_size\n",
    "        # Generate one batch of data\n",
    "        # Generate indices of the batch\n",
    "        index = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        # Find list of IDs\n",
    "        batch = [self.indices[k] for k in index]\n",
    "        x, y = self.data_generation(batch)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Updates indexes after each epoch\n",
    "        \"\"\"\n",
    "        self.index = np.arange(len(self.indices))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.index)\n",
    "\n",
    "    def load(self, image_path, depth_map, mask):\n",
    "        \"\"\"Load input and target image.\"\"\"\n",
    "\n",
    "        image_ = cv2.imread(image_path)\n",
    "        image_ = cv2.cvtColor(image_, cv2.COLOR_BGR2RGB)\n",
    "        image_ = cv2.resize(image_, self.dim)\n",
    "        image_ = tf.image.convert_image_dtype(image_, tf.float32)\n",
    "\n",
    "        depth_map = np.load(depth_map).squeeze()\n",
    "\n",
    "        mask = np.load(mask)\n",
    "        mask = mask > 0\n",
    "\n",
    "        max_depth = min(300, np.percentile(depth_map, 99))\n",
    "        depth_map = np.clip(depth_map, self.min_depth, max_depth)\n",
    "        depth_map = np.log(depth_map, where=mask)\n",
    "\n",
    "        depth_map = np.ma.masked_where(~mask, depth_map)\n",
    "\n",
    "        depth_map = np.clip(depth_map, 0.1, np.log(max_depth))\n",
    "        depth_map = cv2.resize(depth_map, self.dim)\n",
    "        depth_map = np.expand_dims(depth_map, axis=2)\n",
    "        depth_map = tf.image.convert_image_dtype(depth_map, tf.float32)\n",
    "\n",
    "        return image_, depth_map\n",
    "\n",
    "    def data_generation(self, batch):\n",
    "\n",
    "        x = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, *self.dim, 1))\n",
    "\n",
    "        for i, batch_id in enumerate(batch):\n",
    "            x[i,], y[i,] = self.load(\n",
    "                self.data[\"image\"][batch_id],\n",
    "                self.data[\"depth\"][batch_id],\n",
    "                self.data[\"mask\"][batch_id],\n",
    "            )\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_depth_map(samples, test=False, model=None):\n",
    "    input, target = samples\n",
    "    cmap = plt.cm.jet\n",
    "    cmap.set_bad(color=\"black\")\n",
    "\n",
    "    if test:\n",
    "        pred = model.predict(input)\n",
    "        fig, ax = plt.subplots(6, 3, figsize=(50, 50))\n",
    "        for i in range(6):\n",
    "            ax[i, 0].imshow((input[i].squeeze()))\n",
    "            ax[i, 1].imshow((target[i].squeeze()), cmap=cmap)\n",
    "            ax[i, 2].imshow((pred[i].squeeze()), cmap=cmap)\n",
    "\n",
    "    else:\n",
    "        fig, ax = plt.subplots(6, 2, figsize=(50, 50))\n",
    "        for i in range(6):\n",
    "            ax[i, 0].imshow((input[i].squeeze()))\n",
    "            ax[i, 1].imshow((target[i].squeeze()), cmap=cmap)\n",
    "\n",
    "\n",
    "visualize_samples = next(\n",
    "    iter(DataGenerator(data=df, batch_size=6, dim=(HEIGHT, WIDTH)))\n",
    ")\n",
    "visualize_depth_map(visualize_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownscaleBlock(layers.Layer):\n",
    "    def __init__(\n",
    "        self, filters, kernel_size=(3, 3), padding=\"same\", strides=1, **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.convA = layers.Conv2D(filters, kernel_size, strides, padding)\n",
    "        self.convB = layers.Conv2D(filters, kernel_size, strides, padding)\n",
    "        self.reluA = layers.LeakyReLU(alpha=0.2)\n",
    "        self.reluB = layers.LeakyReLU(alpha=0.2)\n",
    "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.pool = layers.MaxPool2D((2, 2), (2, 2))\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        d = self.convA(input_tensor)\n",
    "        x = self.bn2a(d)\n",
    "        x = self.reluA(x)\n",
    "\n",
    "        x = self.convB(x)\n",
    "        x = self.bn2b(x)\n",
    "        x = self.reluB(x)\n",
    "\n",
    "        x += d\n",
    "        p = self.pool(x)\n",
    "        return x, p\n",
    "\n",
    "\n",
    "class UpscaleBlock(layers.Layer):\n",
    "    def __init__(\n",
    "        self, filters, kernel_size=(3, 3), padding=\"same\", strides=1, **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.us = layers.UpSampling2D((2, 2))\n",
    "        self.convA = layers.Conv2D(filters, kernel_size, strides, padding)\n",
    "        self.convB = layers.Conv2D(filters, kernel_size, strides, padding)\n",
    "        self.reluA = layers.LeakyReLU(alpha=0.2)\n",
    "        self.reluB = layers.LeakyReLU(alpha=0.2)\n",
    "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "        self.conc = layers.Concatenate()\n",
    "\n",
    "    def call(self, x, skip):\n",
    "        x = self.us(x)\n",
    "        concat = self.conc([x, skip])\n",
    "        x = self.convA(concat)\n",
    "        x = self.bn2a(x)\n",
    "        x = self.reluA(x)\n",
    "\n",
    "        x = self.convB(x)\n",
    "        x = self.bn2b(x)\n",
    "        x = self.reluB(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class BottleNeckBlock(layers.Layer):\n",
    "    def __init__(\n",
    "        self, filters, kernel_size=(3, 3), padding=\"same\", strides=1, **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.convA = layers.Conv2D(filters, kernel_size, strides, padding)\n",
    "        self.convB = layers.Conv2D(filters, kernel_size, strides, padding)\n",
    "        self.reluA = layers.LeakyReLU(alpha=0.2)\n",
    "        self.reluB = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.convA(x)\n",
    "        x = self.reluA(x)\n",
    "        x = self.convB(x)\n",
    "        x = self.reluB(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthEstimationModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ssim_loss_weight = 0.85\n",
    "        self.l1_loss_weight = 0.1\n",
    "        self.edge_loss_weight = 0.9\n",
    "        self.loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        f = [16, 32, 64, 128, 256]\n",
    "        self.downscale_blocks = [\n",
    "            DownscaleBlock(f[0]),\n",
    "            DownscaleBlock(f[1]),\n",
    "            DownscaleBlock(f[2]),\n",
    "            DownscaleBlock(f[3]),\n",
    "        ]\n",
    "        self.bottle_neck_block = BottleNeckBlock(f[4])\n",
    "        self.upscale_blocks = [\n",
    "            UpscaleBlock(f[3]),\n",
    "            UpscaleBlock(f[2]),\n",
    "            UpscaleBlock(f[1]),\n",
    "            UpscaleBlock(f[0]),\n",
    "        ]\n",
    "        self.conv_layer = layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"tanh\")\n",
    "\n",
    "    def calculate_loss(self, target, pred):\n",
    "        # Edges\n",
    "        dy_true, dx_true = tf.image.image_gradients(target)\n",
    "        dy_pred, dx_pred = tf.image.image_gradients(pred)\n",
    "        weights_x = tf.exp(tf.reduce_mean(tf.abs(dx_true)))\n",
    "        weights_y = tf.exp(tf.reduce_mean(tf.abs(dy_true)))\n",
    "\n",
    "        # Depth smoothness\n",
    "        smoothness_x = dx_pred * weights_x\n",
    "        smoothness_y = dy_pred * weights_y\n",
    "\n",
    "        depth_smoothness_loss = tf.reduce_mean(abs(smoothness_x)) + tf.reduce_mean(\n",
    "            abs(smoothness_y)\n",
    "        )\n",
    "\n",
    "        # Structural similarity (SSIM) index\n",
    "        ssim_loss = tf.reduce_mean(\n",
    "            1\n",
    "            - tf.image.ssim(\n",
    "                target, pred, max_val=WIDTH, filter_size=7, k1=0.01 ** 2, k2=0.03 ** 2\n",
    "            )\n",
    "        )\n",
    "        # Point-wise depth\n",
    "        l1_loss = tf.reduce_mean(tf.abs(target - pred))\n",
    "\n",
    "        loss = (\n",
    "            (self.ssim_loss_weight * ssim_loss)\n",
    "            + (self.l1_loss_weight * l1_loss)\n",
    "            + (self.edge_loss_weight * depth_smoothness_loss)\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_metric]\n",
    "\n",
    "    def train_step(self, batch_data):\n",
    "        input, target = batch_data\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = self(input, training=True)\n",
    "            loss = self.calculate_loss(target, pred)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\n",
    "            \"loss\": self.loss_metric.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, batch_data):\n",
    "        input, target = batch_data\n",
    "\n",
    "        pred = self(input, training=False)\n",
    "        loss = self.calculate_loss(target, pred)\n",
    "\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\n",
    "            \"loss\": self.loss_metric.result(),\n",
    "        }\n",
    "\n",
    "    def call(self, x):\n",
    "        c1, p1 = self.downscale_blocks[0](x)\n",
    "        c2, p2 = self.downscale_blocks[1](p1)\n",
    "        c3, p3 = self.downscale_blocks[2](p2)\n",
    "        c4, p4 = self.downscale_blocks[3](p3)\n",
    "\n",
    "        bn = self.bottle_neck_block(p4)\n",
    "\n",
    "        u1 = self.upscale_blocks[0](bn, c4)\n",
    "        u2 = self.upscale_blocks[1](u1, c3)\n",
    "        u3 = self.upscale_blocks[2](u2, c2)\n",
    "        u4 = self.upscale_blocks[3](u3, c1)\n",
    "\n",
    "        return self.conv_layer(u4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LR,\n",
    "    amsgrad=False,\n",
    ")\n",
    "model = DepthEstimationModel()\n",
    "# Define the loss function\n",
    "cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction=\"none\"\n",
    ")\n",
    "# Compile the model\n",
    "model.compile(optimizer, loss=cross_entropy)\n",
    "\n",
    "train_loader = DataGenerator(\n",
    "    data=df[:260].reset_index(drop=\"true\"), batch_size=BATCH_SIZE, dim=(HEIGHT, WIDTH)\n",
    ")\n",
    "validation_loader = DataGenerator(\n",
    "    data=df[260:].reset_index(drop=\"true\"), batch_size=BATCH_SIZE, dim=(HEIGHT, WIDTH)\n",
    ")\n",
    "model.fit(\n",
    "    train_loader,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = next(\n",
    "    iter(\n",
    "        DataGenerator(\n",
    "            data=df[265:].reset_index(drop=\"true\"), batch_size=6, dim=(HEIGHT, WIDTH)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "visualize_depth_map(test_loader, test=True, model=model)\n",
    "\n",
    "test_loader = next(\n",
    "    iter(\n",
    "        DataGenerator(\n",
    "            data=df[300:].reset_index(drop=\"true\"), batch_size=6, dim=(HEIGHT, WIDTH)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "visualize_depth_map(test_loader, test=True, model=model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
